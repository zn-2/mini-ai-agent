# mini-ai-agent

## ðŸ“˜ GitHub Models Agent
This project calls a single LLM agent via LangChain and GitHub Models using a simple query through a custom `ask()` function that returns a response to the user.


## âœ¨ Features
- Straightforward structure

- `agent.py` contains the LLM agent

- `main.py` calls the agent with a query

- Uses GitHub Models

- Custom `ask()` function for querying the model and returning a userâ€‘friendly response


## ðŸ“‚ Project Structure
```python
mini-ai-agent/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent.py      # LLM & ask() function
â”‚   â”œâ”€â”€ __init__.py
â”‚
â”œâ”€â”€ main.py           # Querying the model
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```


## ðŸš€ Getting Started
**1. Install all dependencies**
```python
pip install -r requirements.txt
```
**2. Create a `.env` file**

Add your GitHub token here:
```python
GITHUB_TOKEN=your_token
```
**3. Run the query script**
```python
python main.py
```
**4. (Optional) Edit query & model**
- In `main.py` you can change the question sent to the model by updating the string.

- In `agent.py` you can change to any compatible GitHub model by updating the `model` parameter in the `ChatOpenAI` function.


## ðŸ§  How It Works
The `ask()` function in `src/agent.py`:

- loads your GitHub Models API key

- initializes the model

- sends a query

- receives the response

- returns it in a userâ€‘friendly format


## ðŸ“„ License
MIT
